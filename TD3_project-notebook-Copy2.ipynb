{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e041c0-4c9e-4640-9b19-0a7a3031a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import laserhockey.hockey_env as h_env\n",
    "import gymnasium as gym\n",
    "from importlib import reload\n",
    "from TD3_helpers import *\n",
    "import time\n",
    "import torch\n",
    "import DDPG\n",
    "import TD3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb840b09-a9c9-41fe-94d2-bfab985004cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_config = {\n",
    "    \"name\" : \"name\",\n",
    "    \"agent_type\" : \"TD3\",\n",
    "    \"env_type\" : \"hockey\",\n",
    "    \"test\" : False,\n",
    "    \"render\" : False,\n",
    "    \"episodes\" : 400,\n",
    "    \"max_steps\" : 50000,\n",
    "    \"mode\" : \"normal\",\n",
    "    \"eps\" : 0.1,\n",
    "    \"discount\":0.99,\n",
    "    \"update_target_every\":100,\n",
    "    \"update_policy_every\":2,\n",
    "    \"hidden_sizes_actor\" : [256,256],\n",
    "    \"hidden_sizes_critic\" : [256,256],\n",
    "    \"iter_fit\" : 1,\n",
    "    \"batch_size\" : 256,\n",
    "    \"smoothing_std\"  : 0.0001,\n",
    "    \"smoothing_clip\" : 0.0002,\n",
    "    \"checkpoint1\" : None,\n",
    "    \"checkpoint2\" : None,\n",
    "    \"learning_rate_critic\": 0.001,\n",
    "    \"learning_rate_actor\": 0.001,\n",
    "    \"buffer_size\" : int(1e6),\n",
    "    \"theta\" : 0.005,\n",
    "    \"prio_replay\" : False,\n",
    "    \"exp_phase\" : 0,\n",
    "    \"cdq\" : True\n",
    "}\n",
    "# lr of 0.0001 for both seems to work best for hockey\n",
    "# lr 0.001 for pendulum\n",
    "# iter_fit 40 for walker, 20 for rest\n",
    "# eps 0.1 seems to be best\n",
    "# discount 1 shows best results (winning later isn't worse than earlier?)\n",
    "# 20 iterations with policy delay 2 best for hockey\n",
    "# fixedactionscomparefinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a72c71-8be0-4134-8422-00072b91c6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT TD3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   9%|\u001b[32m█████▏                                                 \u001b[0m| 94276/1000000 [54:14<10:32:25, 23.87steps/s]\u001b[0m"
     ]
    }
   ],
   "source": [
    "### WEAK EXPERIMENT ###\n",
    "for agent_type in [\"TD3\", \"DDPG\", \"DPU\", \"TPS\", \"CDQ\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"discount\"] = 0.99\n",
    "    config[\"ou\"] = False\n",
    "    config[\"learning_rate_critic\"] = 0.001\n",
    "    config[\"learning_rate_actor\"] = 0.001\n",
    "    config[\"smoothing_std\"] = 0.0001\n",
    "    config[\"smoothing_clip\"] = 0.0002\n",
    "    config[\"exp_phase\"] = int(2e3)\n",
    "    config[\"max_steps\"] = int(1e6)\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"hockey\"\n",
    "    config[\"mode\"] = \"weak\"\n",
    "    config[\"name\"] = \"no_ou_highlr_no_prio_long\"\n",
    "    init_train(config)\n",
    "    config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    config[\"test\"] = True\n",
    "    init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55212b8-bfeb-42e7-a082-f19130ad2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORMAL EXPERIMENT ###\n",
    "for agent_type in [\"TD3\", \"DDPG\", \"DPU\", \"TPS\", \"CDQ\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"discount\"] = 0.99\n",
    "    config[\"learning_rate_critic\"] = 0.001\n",
    "    config[\"learning_rate_actor\"] = 0.001\n",
    "    config[\"exp_phase\"] = 50\n",
    "    config[\"episodes\"] = 1000\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"hockey\"\n",
    "    config[\"mode\"] = \"normal\"\n",
    "    config[\"name\"] = f'agentcomparefinal'\n",
    "    init_train(config)\n",
    "    config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    config[\"test\"] = True\n",
    "    init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64339f0a-553e-4898-aab9-849c9a508749",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PENDULUM EXPERIMENT ###\n",
    "#for agent_type in [\"TD3\", \"DDPG\", \"DPU\", \"TPS\", \"CDQ\"]:\n",
    "for agent_type in [\"CDQ\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"discount\"] = 0.99\n",
    "    config[\"episodes\"] = 50\n",
    "    config[\"max_steps\"] = int(1e4)\n",
    "    config[\"exp_phase\"] = 0\n",
    "    config[\"hidden_sizes_critic\"] = [32,32]\n",
    "    config[\"hidden_sizes_actor\"] = [32,32]\n",
    "    config[\"learning_rate_critic\"] = 0.001\n",
    "    config[\"learning_rate_actor\"] = 0.001\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"pendulum\"\n",
    "    config[\"name\"] = \"pendulum new\"\n",
    "    init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c8014-18ba-4b29-840a-7897db7b0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHEETAH EXPERIMENT ###\n",
    "for agent_type in [ \"TD3\", \"DDPG\", \"DPU\", \"TPS\", \"CDQ\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"discount\"] = 0.99\n",
    "    config[\"episodes\"] = 200\n",
    "    config[\"exp_phase\"] = 20\n",
    "    config[\"max_steps\"] = int(1e5)\n",
    "    config[\"learning_rate_critic\"] = 0.001\n",
    "    config[\"learning_rate_actor\"] = 0.001\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"cheetah\"\n",
    "    config[\"name\"] = \"agentcompare\"\n",
    "    init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee039449-2a54-4d5b-81f0-60ba85c8467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WALKER EXPERIMENT ###\n",
    "for agent_type in [\"DDPG\", \"DPU\", \"TPS\", \"CDQ\", \"TD3\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"episodes\"] = 500\n",
    "    config[\"exp_phase\"] = 50\n",
    "    config[\"max_steps\"] = int(1e5)\n",
    "    config[\"learning_rate_critic\"] = 0.001\n",
    "    config[\"learning_rate_actor\"] = 0.001\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"walker\"\n",
    "    config[\"name\"] = \"agentcompare_long\"\n",
    "    init_train(config)\n",
    "    config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_{config[\"env_type\"]}_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143d058-e5c2-489b-8cf0-85d342cd4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFENSE EXPERIMENT ###\n",
    "for agent_type in [\"TD3\", \"DDPG\", \"DPU\", \"TPS\", \"CDQ\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"episodes\"] = 1000\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"hockey\"\n",
    "    config[\"mode\"] = \"defense\"\n",
    "    config[\"name\"] = \"agentcompare_new\"\n",
    "    init_train(config)\n",
    "    config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    config[\"test\"] = True\n",
    "    init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752bfb0-d1c1-4f24-b631-518799543a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATTACK EXPERIMENT ###\n",
    "for agent_type in [\"DDPG\", \"DPU\", \"TPS\", \"CDQ\", \"TD3\"]:\n",
    "    print(\"AGENT\", agent_type)\n",
    "    config = start_config.copy()\n",
    "    config[\"episodes\"] = 1000\n",
    "    config[\"agent_type\"] = agent_type\n",
    "    config[\"env_type\"] = \"hockey\"\n",
    "    config[\"mode\"] = \"attack\"\n",
    "    config[\"name\"] = f'env_{config[\"env_type\"]}_agent_{agent_type}'\n",
    "    init_train(config)\n",
    "    config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea4eba-fa05-4b6b-871d-d47e6a2f1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING CAMP ###\n",
    "config = start_config.copy()\n",
    "# defense training\n",
    "config[\"name\"] = \"traincamp_new\"\n",
    "config[\"env_type\"] = \"hockey\"\n",
    "config[\"mode\"] = \"defense\"\n",
    "config[\"episodes\"] = 500\n",
    "init_train(config)\n",
    "config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "# test agent trained on defense\n",
    "config[\"mode\"] = \"weak\"\n",
    "config[\"test\"] = True\n",
    "init_train(config)\n",
    "\n",
    "# shoot training\n",
    "config[\"mode\"] = \"attack\"\n",
    "config[\"episodes\"] = 500\n",
    "config[\"test\"] = False\n",
    "init_train(config)\n",
    "config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "# test agent trained on defense AND shooting\n",
    "config[\"mode\"] = \"weak\"\n",
    "config[\"test\"] = True\n",
    "init_train(config)\n",
    "\n",
    "# regular training\n",
    "config[\"mode\"] = \"weak\"\n",
    "config[\"episodes\"] = 1000\n",
    "config[\"test\"] = False\n",
    "init_train(config)\n",
    "config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "# test agent trained on defense AND shooting\n",
    "config[\"mode\"] = \"normal\"\n",
    "config[\"test\"] = True\n",
    "init_train(config)\n",
    "\n",
    "# regular training\n",
    "config[\"mode\"] = \"normal\"\n",
    "config[\"episodes\"] = 1000\n",
    "config[\"test\"] = False\n",
    "init_train(config)\n",
    "config[\"checkpoint1\"] = f'./results/{config[\"agent_type\"]}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "# test agent trained on defense AND shooting\n",
    "config[\"mode\"] = \"normal\"\n",
    "config[\"test\"] = True\n",
    "init_train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9885a20-f384-483c-ab15-35a8d735f46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### priority replay !!!NOT USED!!! ###\n",
    "for pri in [True, False]:\n",
    "    config = start_config.copy()\n",
    "    config[\"episodes\"] = 5000\n",
    "    config[\"prio_replay\"] = pri\n",
    "    config[\"name\"] = f\"prio_{pri}\"\n",
    "    config[\"mode\"] = \"normal\"\n",
    "    agent_type=\"TD3\"\n",
    "    env_type=\"hockey\"\n",
    "    init_train(agent_type, env_type, config)\n",
    "    config[\"checkpoint1\"] = f'./results/{agent_type}_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    # test agent\n",
    "    config[\"mode\"] = \"normal\"\n",
    "    config[\"test\"] = True\n",
    "    #config[\"episodes\"] = 10\n",
    "    #config[\"render\"] = True\n",
    "    init_train(agent_type, env_type, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bffc2-4fe0-40a6-964a-6bf7ff78a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT USED ###\n",
    "config = start_config.copy()\n",
    "config[\"episodes\"] = 1000\n",
    "config[\"name\"] = \"20ktest\"\n",
    "for i in range(1):\n",
    "    if i>0:\n",
    "        config[\"mode\"] = \"selfplay\"\n",
    "    config[\"checkpoint1\"] = f'./results/TD3Agent_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    config[\"checkpoint2\"] = f'./results/TD3Agent_hockey_{config[\"name\"]}_{config[\"mode\"]}_agent.pth'\n",
    "    config[\"name\"] = f\"selfplay{i}\"\n",
    "    config[\"mode\"] = \"selfplay\"\n",
    "    config[\"test\"] = False\n",
    "    init_train(config)\n",
    "    config[\"test\"] = True\n",
    "    config[\"mode\"] = \"normal\"\n",
    "    config[\"checkpoint2\"] = None\n",
    "    init_train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
